{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORMGP hydrological raster preparation (OWRC23)\n",
    "This notebook documents the creation of a set of upscaled rasters needed for watershed characterization. Version 2023.\n",
    "\n",
    "All data needed in the `input/` directory can be accessed [here](https://www.dropbox.com/scl/fo/bfkxkkrz940eqkdsk9cqy/AJadVHg9De-SdPWFORDCIHE?rlkey=tndynpc63rclqc8tu527cxg0d&dl=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load land-use data\n",
    "The primary source of the land-use data is: *Ministry of Natural Resources and Forestry, 2019. Southern Ontario Land Resource Information System (SOLRIS) Version 3.0: Data Specifications. Science and Research Branch, April 2019.* In areas to the north where SOLRIS does not cover, *Agriculture and Agri-food Canada, 2013. Data Product Specifications (ISO 19131) rev. A. 31pp.* was used as infill. More information can be found [here](https://owrc.github.io/interpolants/interpolation/landuse.html).\n",
    "\n",
    "The land-use data has been compiled as a 21,800x19,344 15m grid that is here upscaled to a 5450x4836, 60m grid. The following code collects the 4x4 15m sub-grids that are aggregated (by the most-present ID) to every 60m cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19344, 21800)\n",
      "(26356200, 16)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import imageio\n",
    "\n",
    "with rasterio.open(\"input/landuse23.tif\") as f: r = f.read()[0]\n",
    "print(r.shape)\n",
    "s = np.array(r, np.uint8).reshape(4836, 4, -1, 4).swapaxes(1,2).reshape(-1, 4*4)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, cross-referencing is accomplished to i) gather all unique SOLRIS IDs and ii) create an indexed grid referencing these unique IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11  21  23  41  43  52  53  64  65  81  82  83  90  91  92  93 131 135\n",
      " 140 150 160 170 191 192 193 201 202 203 204 205 250 255]\n"
     ]
    }
   ],
   "source": [
    "u, ix = np.unique(s, return_inverse=True)\n",
    "ix = ix.reshape(s.shape)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line up-scales the SOLRIS IDs by assigning the dominant SOLRIS ID to every 60m cell, and saves the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4836, 5450)\n"
     ]
    }
   ],
   "source": [
    "s60 = u[np.argmax(np.apply_along_axis(np.bincount, 1, ix.reshape(-1, 4*4 ), None, np.max(ix) + 1), axis=1)].reshape(4836,5450)\n",
    "print(s60.shape)\n",
    "s60.tofile(\"output/landuse23_60.bil\")\n",
    "imageio.imwrite('output/landuse23_60.png', s60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregates\n",
    "Next, up-scaling of land use properties (imperviousness, canopy cover, etc.) is computed by averaging the (16-cell sub-grid) 15m values over the 60m cell.\n",
    "\n",
    "#### load lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"input/lookup_200731.csv\").fillna(0.0)\n",
    "df['PerOW'] = np.select([df['Value'] == 170], [1.0], 0.0)\n",
    "df['PerWL'] = np.select([(df['Value'] >= 131) & (df['Value'] <= 160)], [1.0], 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fraction of impervious cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimp = {i:0. for i in u}\n",
    "# dimp[201] = .85\n",
    "# dimp[202] = .1\n",
    "# dimp[203] = .90\n",
    "dimp = pd.Series(df.PerImp.values,index=df.Value).to_dict()\n",
    "dimp[255] = 0.\n",
    "# print(dimp)\n",
    "\n",
    "perimp = np.mean(np.vectorize(dimp.get)(s), 1).reshape(s60.shape)\n",
    "perimp.astype(np.float32).tofile(\"output/landuse23_60_perimp.bil\")\n",
    "imageio.imwrite('output/landuse23_60_perimp.png', (perimp*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fraction of canopy cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcov = pd.Series(df.PerCov.values,index=df.Value).to_dict()\n",
    "dcov[255] = 0.\n",
    "\n",
    "percov = np.mean(np.vectorize(dcov.get)(s), 1).reshape(s60.shape)\n",
    "percov.astype(np.float32).tofile(\"output/landuse23_60_percov.bil\")\n",
    "imageio.imwrite('output/landuse23_60_percov.png', (percov*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fraction water body cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = pd.Series(df.PerOW.values,index=df.Value).to_dict()\n",
    "dow[255] = 0.\n",
    "\n",
    "perow = np.mean(np.vectorize(dow.get)(s), 1).reshape(s60.shape)\n",
    "perow.astype(np.float32).tofile(\"output/landuse23_60_perow.bil\")\n",
    "imageio.imwrite('output/landuse23_60_perow.png', (perow*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fraction wetland cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwl = pd.Series(df.PerWL.values,index=df.Value).to_dict()\n",
    "dwl[255] = 0.\n",
    "\n",
    "perwl = np.mean(np.vectorize(dwl.get)(s), 1).reshape(s60.shape)\n",
    "perwl.astype(np.float32).tofile(\"output/landuse23_60_perwl.bil\")\n",
    "imageio.imwrite('output/landuse23_60_perwl.png', (perwl*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load surficial geology data\n",
    "The source of the surficial geology data is: *Ontario Geological Survey 2010. Surficial geology of southern Ontario; Ontario Geological Survey, Miscellaneous Release— Data 128 – Revised.* In some areas, an infilling procedure was applied where data were unavailable; for more information, see [here](https://owrc.github.io/interpolants/interpolation/surfgeo.html).\n",
    "\n",
    "The raster loaded below has been build using QGIS, no further processing required here. The raster represents a [1,8] index referring to the \"permeability\" attribute (OGS, 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19344, 21800)\n",
      "(26356200, 16)\n"
     ]
    }
   ],
   "source": [
    "with rasterio.open(\"input/surfgeo23.tif\") as f: r = f.read()[0]\n",
    "print(r.shape)\n",
    "g = np.array(r, np.uint8).reshape(4836, 4, -1, 4).swapaxes(1,2).reshape(-1, 4*4)\n",
    "print(g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-referencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  10  20  21  22  30  40  41  50  51  52  53  54  55  60  61  62  70\n",
      "  71  72  80  81  82  90  91  92  93 120 130 142 143 170 190 200 210]\n"
     ]
    }
   ],
   "source": [
    "u, ix = np.unique(g, return_inverse=True)\n",
    "ix = ix.reshape(g.shape)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up-scales the surficial geology IDs by assigning the dominant ID to every 60m cell, and saves the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4836, 5450)\n"
     ]
    }
   ],
   "source": [
    "g60 = u[np.argmax(np.apply_along_axis(np.bincount, 1, ix.reshape(-1, 4*4 ), None, np.max(ix) + 1), axis=1)].reshape(4836,5450)\n",
    "print(g60.shape)\n",
    "g60.tofile(\"output/surfgeo23_60.bil\")\n",
    "imageio.imwrite('output/surfgeo23_60.png', g60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the OGS permeability attributes (High, Medium-high, ... , organics, etc.) are converted to an effective hydraulic conductivity, log-scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dperm = {0: 'Variable', 10: 'Variable', 20: 'Variable', 21: 'Variable', 22: 'Variable', 30: 'Variable', 40: 'Variable', 41: 'Variable', \n",
    "         50: 'Medium', 51: 'Medium', 52: 'Low-Medium', 53: 'Medium', 54: 'Low', 55: 'Variable', 60: 'High', 61: 'High', 62: 'High', 70: 'High', 71: 'High', 72: 'High', \n",
    "         80: 'Low', 81: 'Low', 82: 'Low', 90: 'High', 91: 'High', 92: 'High', 93: 'High', 120: 'Fluvial', 130: 'Low', 140: 'High', 142: 'High', 143: 'High', \n",
    "         170: 'Medium-High', 190: 'Fluvial', 200: 'Organic', 210: 'Variable'}\n",
    "dkref = {'Low': -9., 'Low-Medium': -8., 'Medium': -7., 'Medium-High': -6., 'High': -5., 'Variable': -8., 'Fluvial': -5., 'Organic': -6.} # {1: -9., 2: -8., 3: -7., 4: -6., 5: -5., 6: -8., 7: -5., 8: -6.}\n",
    "dsg = {x: dkref[y] for x,y in dperm.items()}\n",
    "\n",
    "# geometric mean\n",
    "gk = np.mean(np.vectorize(dsg.get)(g), 1).reshape(g60.shape)\n",
    "gk.astype(np.float32).tofile(\"output/surfgeo23_60-logK.bil\")\n",
    "imageio.imwrite('output/surfgeo23_60-logK.png', (gk*-28).astype(np.uint8))\n",
    "\n",
    "# # assigned to dominant class\n",
    "# gk = np.vectorize(dsg.get)(g60)\n",
    "# gk.astype(np.float32).tofile(\"output/surfgeo23_60-logK-dominant.bil\")\n",
    "# imageio.imwrite('output/surfgeo23_60-logK-dominant.png', (gk*-28).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, create a raster of indexed permeability types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diref = {'Low': 1, 'Low-Medium': 2, 'Medium': 3, 'Medium-High': 4, 'High': 5, 'Variable': 6, 'Fluvial': 7, 'Organic': 8} \n",
    "disg = {x: diref[y] for x,y in dperm.items()}\n",
    "\n",
    "# assigned to dominant class\n",
    "gisg = np.vectorize(disg.get)(g60)\n",
    "gisg.astype(np.uint8).tofile(\"output/surfgeo23_60-iperm-dominant.bil\")\n",
    "imageio.imwrite('output/surfgeo23_60-iperm-dominant.png', (gisg*31).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-watershed aggregation\n",
    "The ORMGP jurisdiction has been sub-divided into 4,238 ~10km² sub-watersheds and is provided as an index raster. Using a zonal analysis, raster values aggregated above are further aggregated to every sub-watershed.\n",
    "\n",
    "#### SWS index raster and *\"indicize\"*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.fromfile(\"input/PDEM-South-D2013-OWRC25-60-HC-sws10.bil\", np.int32).reshape(4836,5450)\n",
    "_, iw = np.unique(w, return_inverse=True)\n",
    "imageio.imwrite('output/PDEM-South-D2013-OWRC25-60-HC-sws10.png', np.array(1-iw.reshape(4836,5450)/iw.max()*255, np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect zonal summations and build dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.unique(w, return_counts=True)\n",
    "sgk = np.bincount(iw, weights=gk.flatten())\n",
    "spi = np.bincount(iw, weights=perimp.flatten())\n",
    "spc = np.bincount(iw, weights=percov.flatten())\n",
    "sow = np.bincount(iw, weights=perow.flatten())\n",
    "swl = np.bincount(iw, weights=perwl.flatten())\n",
    "\n",
    "df = pd.DataFrame(data=dict(swsid=n[0],n=n[1],perm=sgk/n[1],perimp=spi/n[1],percov=spc/n[1],perow=sow/n[1],perwl=swl/n[1]))\n",
    "df = df[df.swsid != -9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create additional fields where indices are counted per sub-watershed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def swscounts(a,b):\n",
    "    tups = list(zip(a.flatten(),b.flatten()))\n",
    "    dout = dict()\n",
    "    for k,v in tups: \n",
    "        if k==-9999: continue\n",
    "        if v==255: continue\n",
    "        if not k in dout: dout[k]=dict()\n",
    "        if not v in dout[k]: dout[k][int(v)]=0\n",
    "        dout[k][v]+=1\n",
    "    djson = dict()\n",
    "    for k,v in dout.items():\n",
    "        djson[k] = json.dumps(v)\n",
    "    return djson\n",
    "\n",
    "df['LUcnt'] = df['swsid'].map(swscounts(w,s60))\n",
    "df['SGcnt'] = df['swsid'].map(swscounts(w,g60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert \"effective\" permeabilities back to OGS (2010) qualitative terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dperm = {-9.: 'low', -8.: 'low-medium', -7.: 'medium', -6.: 'medium-high', -5.: 'high'}\n",
    "df.perm = round(df.perm,0)\n",
    "df.replace({\"perm\": dperm}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this index dataframe is merged to the sub-watershed polygon shapefile, exported as geojson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         swsid     n        perm    perimp    percov     perow     perwl  \\\n",
      "1       242569    78      medium  0.000000  1.000000  0.000000  0.000000   \n",
      "2       248113   230      medium  0.000000  0.950951  0.036141  0.016033   \n",
      "3       395236  3126      medium  0.000000  0.905600  0.059681  0.046525   \n",
      "4       422516    82  low-medium  0.000000  1.000000  0.000000  0.000000   \n",
      "5       536857  3433  low-medium  0.000000  0.896200  0.080414  0.040762   \n",
      "...        ...   ...         ...       ...       ...       ...       ...   \n",
      "4227  25970930  4211  low-medium  0.046343  0.131015  0.089409  0.281569   \n",
      "4228  26069029  1062  low-medium  0.087953  0.153990  0.091337  0.230638   \n",
      "4229  26107113   951         low  0.013972  0.061126  0.000000  0.075184   \n",
      "4230  26145358  1470  low-medium  0.149972  0.090351  0.115136  0.067304   \n",
      "4231  26161646   456         low  0.061739  0.021519  0.006442  0.000000   \n",
      "\n",
      "                                                  LUcnt  \\\n",
      "1                        {\"93\": 25, \"92\": 20, \"91\": 33}   \n",
      "2     {\"93\": 192, \"131\": 5, \"52\": 2, \"92\": 17, \"170\"...   \n",
      "3     {\"93\": 1829, \"92\": 616, \"91\": 315, \"131\": 135,...   \n",
      "4                        {\"93\": 38, \"92\": 20, \"91\": 24}   \n",
      "5     {\"93\": 1986, \"92\": 705, \"91\": 337, \"131\": 121,...   \n",
      "...                                                 ...   \n",
      "4227  {\"250\": 718, \"193\": 1405, \"131\": 344, \"170\": 3...   \n",
      "4228  {\"250\": 238, \"170\": 103, \"131\": 175, \"201\": 41...   \n",
      "4229  {\"250\": 132, \"193\": 721, \"131\": 70, \"93\": 19, ...   \n",
      "4230  {\"250\": 256, \"203\": 59, \"193\": 314, \"201\": 134...   \n",
      "4231  {\"193\": 249, \"202\": 27, \"191\": 1, \"203\": 7, \"2...   \n",
      "\n",
      "                                                  SGcnt  \n",
      "1              {\"21\": 30, \"70\": 31, \"20\": 11, \"200\": 6}  \n",
      "2             {\"21\": 95, \"10\": 81, \"70\": 28, \"200\": 26}  \n",
      "3     {\"21\": 805, \"10\": 1340, \"70\": 398, \"200\": 466,...  \n",
      "4                                            {\"10\": 82}  \n",
      "5     {\"10\": 1879, \"21\": 1065, \"70\": 195, \"20\": 96, ...  \n",
      "...                                                 ...  \n",
      "4227  {\"81\": 2816, \"190\": 1079, \"90\": 82, \"30\": 13, ...  \n",
      "4228  {\"210\": 227, \"81\": 650, \"190\": 68, \"142\": 35, ...  \n",
      "4229                             {\"81\": 730, \"54\": 221}  \n",
      "4230  {\"142\": 165, \"81\": 1086, \"170\": 41, \"90\": 61, ...  \n",
      "4231          {\"81\": 22, \"170\": 3, \"142\": 3, \"54\": 428}  \n",
      "\n",
      "[4231 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "df.to_csv(\"output/PDEM-South-D2013-OWRC25-60-HC-sws10-summary.csv\",index=False)\n",
    "\n",
    "gdf = gpd.read_file('input/PDEM-South-D2013-OWRC25-60-HC-sws10.geojson')\n",
    "joined_gdf = gdf.merge(df, left_on='SubId', right_on=\"swsid\")\n",
    "joined_gdf.to_file('output/PDEM-South-D2013-OWRC25-60-HC-sws10.geojson', driver=\"GeoJSON\")\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
